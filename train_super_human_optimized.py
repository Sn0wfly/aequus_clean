#!/usr/bin/env python3
"""
üöÄ ENTRENAMIENTO SUPER-HUMANO OPTIMIZADO
Script para entrenar el mejor modelo de poker CFR posible
"""

import sys
import os
import time
import logging

# Setup logging optimizado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('training_superhuman.log')
    ]
)
logger = logging.getLogger(__name__)

# Add path
sys.path.append('.')

try:
    from poker_bot.core.trainer import (
        SuperHumanTrainerConfig, 
        PokerTrainer,
        create_super_human_trainer
    )
    logger.info("‚úÖ M√≥dulos importados correctamente")
except ImportError as e:
    logger.error(f"‚ùå Error importando m√≥dulos: {e}")
    sys.exit(1)

def run_superhuman_training():
    """
    Ejecuta entrenamiento super-humano optimizado
    """
    logger.info("\n" + "="*80)
    logger.info("üöÄ INICIANDO ENTRENAMIENTO SUPER-HUMANO CFR")
    logger.info("="*80)
    logger.info("üéØ OBJETIVO: Crear un bot de poker de nivel √©lite")
    logger.info("üß† SISTEMA: CFR con historiales reales + JAX optimizado")
    logger.info("üèÜ META: Poker IQ 60+ en 100 iteraciones")
    logger.info("="*80)
    
    # Configuraci√≥n super-humana optimizada
    config = SuperHumanTrainerConfig()
    
    # CUSTOMIZACI√ìN PARA M√ÅXIMO RENDIMIENTO
    config.batch_size = 256              # M√°s muestras por iteraci√≥n
    config.max_iterations = 200          # Entrenamiento s√≥lido 
    config.save_interval = 25            # Guardar frecuente
    config.learning_rate = 0.015         # Learning rate optimizado
    
    # Factores de awareness mejorados
    config.position_awareness_factor = 0.4   # Awareness fuerte
    config.suited_awareness_factor = 0.3     # Suited recognition
    config.pot_odds_factor = 0.25           # Pot odds consideration
    
    # Thresholds calibrados para poker avanzado
    config.strong_hand_threshold = 3800     # Solo verdaderas premium
    config.weak_hand_threshold = 1400       # Threshold estricto
    config.bluff_threshold = 700            # Bluffs selectivos
    
    logger.info("‚öôÔ∏è  CONFIGURACI√ìN SUPER-HUMANA:")
    logger.info(f"   - Batch size: {config.batch_size}")
    logger.info(f"   - Max iterations: {config.max_iterations}")
    logger.info(f"   - Learning rate: {config.learning_rate}")
    logger.info(f"   - Position awareness: {config.position_awareness_factor}")
    logger.info(f"   - Suited awareness: {config.suited_awareness_factor}")
    logger.info(f"   - Strong hand threshold: {config.strong_hand_threshold}")
    
    # Crear trainer
    trainer = PokerTrainer(config)
    
    # PATHS para modelos
    base_path = "models/superhuman_cfr"
    os.makedirs("models", exist_ok=True)
    
    logger.info(f"\nüíæ PATHS DE GUARDADO:")
    logger.info(f"   - Base path: {base_path}")
    logger.info(f"   - Checkpoints cada: {config.save_interval} iteraciones")
    
    # ENTRENAMIENTO
    start_time = time.time()
    
    try:
        logger.info("\nüöÄ INICIANDO ENTRENAMIENTO...")
        trainer.train(
            num_iterations=config.max_iterations,
            save_path=base_path,
            save_interval=config.save_interval,
            snapshot_iterations=[50, 100, 150, 200]  # Snapshots frecuentes
        )
        
        total_time = time.time() - start_time
        
        logger.info("\n" + "="*80)
        logger.info("üéâ ENTRENAMIENTO SUPER-HUMANO COMPLETADO")
        logger.info("="*80)
        logger.info(f"‚è±Ô∏è  Tiempo total: {total_time:.1f}s ({total_time/60:.1f} min)")
        logger.info(f"üöÄ Velocidad: {config.max_iterations/total_time:.2f} iter/s")
        logger.info(f"üéØ Hands procesadas: ~{config.max_iterations * config.batch_size * 30:,}")
        
        # Modelo final
        final_model = f"{base_path}_final.pkl"
        logger.info(f"\nüèÜ MODELO FINAL GUARDADO: {final_model}")
        
        # Verificar tama√±o
        if os.path.exists(final_model):
            size_mb = os.path.getsize(final_model) / 1024 / 1024
            logger.info(f"üìä Tama√±o del modelo: {size_mb:.1f} MB")
            
            if size_mb > 2.5:
                logger.info("‚úÖ Modelo grande = Mayor exploraci√≥n de info sets")
            else:
                logger.info("‚ÑπÔ∏è  Modelo compacto = Eficiente para esta fase")
        
        logger.info("\nüéØ PR√ìXIMOS PASOS:")
        logger.info("   1. Revisar logs para Poker IQ progression")
        logger.info("   2. Testear modelo contra oponentes")
        logger.info("   3. Si IQ>60: Listo para producci√≥n")
        logger.info("   4. Si IQ<60: Aumentar iteraciones o ajustar config")
        logger.info("="*80)
        
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  ENTRENAMIENTO INTERRUMPIDO POR USUARIO")
        logger.info("üíæ Checkpoints guardados est√°n disponibles")
        
    except Exception as e:
        logger.error(f"\nüí• ERROR DURANTE ENTRENAMIENTO: {e}")
        import traceback
        logger.error(f"Traceback completo:\n{traceback.format_exc()}")
        raise

def quick_validation_test():
    """
    Test r√°pido para verificar que todo funciona antes del entrenamiento largo
    """
    logger.info("\nüîç EJECUTANDO VALIDACI√ìN PRE-ENTRENAMIENTO...")
    
    # Test config simple
    config = SuperHumanTrainerConfig()
    config.batch_size = 64
    config.max_iterations = 5  # Solo 5 iteraciones para test
    config.save_interval = 5
    
    trainer = PokerTrainer(config)
    
    # Test path
    test_path = "models/test_validation"
    os.makedirs("models", exist_ok=True)
    
    try:
        trainer.train(
            num_iterations=5,
            save_path=test_path,
            save_interval=5
        )
        
        logger.info("‚úÖ VALIDACI√ìN EXITOSA - Sistema listo para entrenamiento largo")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå VALIDACI√ìN FALLIDA: {e}")
        return False

if __name__ == "__main__":
    logger.info("üéÆ POKER CFR SUPER-HUMAN TRAINER")
    
    # Verificar argumentos
    import argparse
    parser = argparse.ArgumentParser(description='Entrenamiento super-humano de poker CFR')
    parser.add_argument('--quick-test', action='store_true', 
                       help='Ejecutar test r√°pido de validaci√≥n solamente')
    parser.add_argument('--full-train', action='store_true',
                       help='Ejecutar entrenamiento completo')
    
    args = parser.parse_args()
    
    if args.quick_test:
        logger.info("üß™ MODO: Test r√°pido de validaci√≥n")
        success = quick_validation_test()
        if success:
            logger.info("\n‚úÖ SISTEMA VALIDADO - Ejecutar con --full-train para entrenamiento completo")
        else:
            logger.error("\n‚ùå VALIDACI√ìN FALLIDA - Revisar errores antes de continuar")
            sys.exit(1)
            
    elif args.full_train:
        logger.info("üöÄ MODO: Entrenamiento completo super-humano")
        run_superhuman_training()
        
    else:
        logger.info("üìã USO:")
        logger.info("   python train_super_human_optimized.py --quick-test    # Test r√°pido")
        logger.info("   python train_super_human_optimized.py --full-train    # Entrenamiento completo")
        logger.info("\nüí° RECOMENDACI√ìN: Ejecutar --quick-test primero") 