#!/usr/bin/env python3
"""
DEBUG SCRIPT: Investigar por qu√© CFR no est√° aprendiendo
Problema: Todas las estrategias permanecen en 0.500 (uniforme)
"""

import jax
import jax.numpy as jnp
import numpy as np
from poker_bot.core.trainer import (
    PokerTrainer, TrainerConfig, _jitted_train_step,
    unified_batch_simulation, compute_advanced_info_set
)

def debug_regret_accumulation():
    """Debuggear paso a paso por qu√© los regrets no se acumulan"""
    print("üîç DEBUGGING: Acumulaci√≥n de Regrets")
    print("="*50)
    
    config = TrainerConfig()
    config.batch_size = 8  # Peque√±o para debugging
    
    # Estado inicial
    regrets = jnp.zeros((config.max_info_sets, config.num_actions), dtype=jnp.float32)
    strategy = jnp.ones((config.max_info_sets, config.num_actions), dtype=jnp.float32) / config.num_actions
    
    key = jax.random.PRNGKey(42)
    
    print(f"üìä Estado inicial:")
    print(f"   - Regrets shape: {regrets.shape}")
    print(f"   - Strategy shape: {strategy.shape}")
    print(f"   - Regrets iniciales (muestra): {regrets[1000:1005, :3]}")
    print(f"   - Strategy inicial (muestra): {strategy[1000:1005, :3]}")
    
    # Ejecutar UN paso y ver qu√© pasa
    print(f"\nüîÑ Ejecutando UN paso de CFR...")
    
    new_regrets, new_strategy = _jitted_train_step(regrets, strategy, key)
    
    print(f"\nüìà Despu√©s de UN paso:")
    print(f"   - Regrets cambiaron: {not jnp.allclose(regrets, new_regrets)}")
    print(f"   - Strategy cambi√≥: {not jnp.allclose(strategy, new_strategy)}")
    
    if not jnp.allclose(regrets, new_regrets):
        regret_diff = jnp.abs(new_regrets - regrets)
        max_change = jnp.max(regret_diff)
        print(f"   - M√°ximo cambio en regrets: {max_change}")
        
        # Buscar los info sets que m√°s cambiaron
        max_change_idx = jnp.unravel_index(jnp.argmax(regret_diff), regret_diff.shape)
        print(f"   - Info set con m√°s cambio: {max_change_idx[0]}, acci√≥n {max_change_idx[1]}")
        print(f"   - Regret antes: {regrets[max_change_idx]}")
        print(f"   - Regret despu√©s: {new_regrets[max_change_idx]}")
    else:
        print("   ‚ùå ¬°LOS REGRETS NO CAMBIARON!")
    
    if not jnp.allclose(strategy, new_strategy):
        strategy_diff = jnp.abs(new_strategy - strategy)
        max_strategy_change = jnp.max(strategy_diff)
        print(f"   - M√°ximo cambio en strategy: {max_strategy_change}")
    else:
        print("   ‚ùå ¬°LA ESTRATEGIA NO CAMBI√ì!")
    
    # An√°lisis detallado del problema
    print(f"\nüîç AN√ÅLISIS DETALLADO:")
    
    # Verificar si hay regrets positivos
    positive_regrets = jnp.maximum(new_regrets, 0.0)
    regret_sums = jnp.sum(positive_regrets, axis=1, keepdims=True)
    
    non_zero_regrets = jnp.sum(regret_sums > 1e-6)
    print(f"   - Info sets con regrets > 1e-6: {non_zero_regrets} de {config.max_info_sets}")
    print(f"   - M√°ximo regret sum: {jnp.max(regret_sums)}")
    print(f"   - M√≠nimo regret sum: {jnp.min(regret_sums)}")
    
    # Muestras de regret sums
    sample_regret_sums = regret_sums[1000:1010].flatten()
    print(f"   - Muestra de regret sums: {sample_regret_sums}")
    
    return new_regrets, new_strategy

def debug_game_simulation():
    """Debuggear si la simulaci√≥n genera datos v√°lidos"""
    print("\nüéÆ DEBUGGING: Simulaci√≥n de Juegos")
    print("="*50)
    
    key = jax.random.PRNGKey(123)
    keys = jax.random.split(key, 8)  # 8 juegos
    
    payoffs, histories, game_results = unified_batch_simulation(keys)
    
    print(f"üìä Resultados de simulaci√≥n:")
    print(f"   - Payoffs shape: {payoffs.shape}")
    print(f"   - Histories shape: {histories.shape}")
    print(f"   - Game results keys: {list(game_results.keys())}")
    
    # Analizar payoffs
    print(f"\nüí∞ An√°lisis de Payoffs:")
    print(f"   - Payoffs √∫nicos: {len(jnp.unique(payoffs))}")
    print(f"   - Rango payoffs: [{jnp.min(payoffs):.2f}, {jnp.max(payoffs):.2f}]")
    print(f"   - Std payoffs: {jnp.std(payoffs):.4f}")
    
    # Muestra de payoffs
    print(f"   - Muestra payoffs juego 0: {payoffs[0]}")
    print(f"   - Muestra payoffs juego 1: {payoffs[1]}")
    
    # Analizar historiales
    print(f"\nüìú An√°lisis de Historiales:")
    valid_actions = histories[histories >= 0]
    print(f"   - Acciones v√°lidas: {len(valid_actions)}")
    print(f"   - Acciones √∫nicas: {jnp.unique(valid_actions)}")
    
    if len(valid_actions) > 0:
        print(f"   - Distribuci√≥n de acciones:")
        for action in range(6):
            count = jnp.sum(valid_actions == action)
            percentage = count / len(valid_actions) * 100
            print(f"     Acci√≥n {action}: {count} ({percentage:.1f}%)")
    else:
        print("   ‚ùå ¬°NO HAY ACCIONES V√ÅLIDAS!")
    
    # Analizar info sets
    print(f"\nüéØ An√°lisis de Info Sets:")
    info_sets_found = []
    
    for game_idx in range(min(3, payoffs.shape[0])):  # Solo 3 juegos
        for player_idx in range(6):
            try:
                info_set_idx = compute_advanced_info_set(game_results, player_idx, game_idx)
                info_sets_found.append(int(info_set_idx))
            except Exception as e:
                print(f"   ‚ùå Error computing info set {game_idx}-{player_idx}: {e}")
    
    if info_sets_found:
        unique_info_sets = len(set(info_sets_found))
        print(f"   - Info sets √∫nicos generados: {unique_info_sets}")
        print(f"   - Total info sets: {len(info_sets_found)}")
        print(f"   - Rango info sets: [{min(info_sets_found)}, {max(info_sets_found)}]")
        print(f"   - Muestra info sets: {info_sets_found[:10]}")
    else:
        print("   ‚ùå ¬°NO SE GENERARON INFO SETS!")
    
    return payoffs, histories, game_results

def debug_cfr_math():
    """Debuggear la matem√°tica del CFR paso a paso"""
    print("\nüìê DEBUGGING: Matem√°tica CFR")
    print("="*50)
    
    # Simular un caso simple con payoffs conocidos
    print("üßÆ Simulando caso CFR simple...")
    
    # Crear un batch peque√±o con payoffs controlados
    payoffs = jnp.array([
        [10.0, -2.0, -2.0, -2.0, -2.0, -2.0],  # Jugador 0 gana
        [-2.0, 15.0, -2.0, -2.0, -2.0, -2.0],  # Jugador 1 gana
        [-2.0, -2.0, 8.0, -2.0, -2.0, -2.0],   # Jugador 2 gana
    ])
    
    print(f"   - Payoffs de prueba: {payoffs.shape}")
    print(f"   - Juego 0: {payoffs[0]}")
    print(f"   - Juego 1: {payoffs[1]}")
    print(f"   - Juego 2: {payoffs[2]}")
    
    # Simular que todos los jugadores tienen el mismo info set para simplificar
    test_info_set = 1000
    
    # Calcular regrets manualmente para el jugador 0 en cada juego
    print(f"\nüéØ Calculando regrets para info set {test_info_set}:")
    
    for game_idx in range(3):
        for player_idx in range(3):  # Solo primeros 3 jugadores
            player_payoff = payoffs[game_idx, player_idx]
            
            print(f"\n   Juego {game_idx}, Jugador {player_idx}:")
            print(f"   - Payoff real: {player_payoff}")
            
            # En CFR, regret = valor_acci√≥n - valor_esperado
            # Valor esperado = payoff actual (estrategia seguida)
            expected_value = player_payoff
            
            # Simular valores de acciones
            for action in range(6):
                # El valor de una acci√≥n depende de si habr√≠amos ganado/perdido m√°s
                if action == 0:  # FOLD
                    action_value = -1.0 if player_payoff > 0 else 0.0  # Evita p√©rdidas pero pierde ganancias
                elif action <= 2:  # CHECK/CALL (pasivo)
                    action_value = player_payoff * 0.8  # Conservador
                else:  # BET/RAISE/ALLIN (agresivo)
                    action_value = player_payoff * 1.2 if player_payoff > 0 else player_payoff * 1.5
                
                regret = action_value - expected_value
                print(f"     Acci√≥n {action}: valor={action_value:.2f}, regret={regret:.2f}")
    
    return payoffs

def main():
    """Ejecutar todos los debugging tests"""
    print("üö® DEBUGGING CFR - ESTRATEGIAS NO APRENDEN")
    print("="*60)
    
    # Test 1: Verificar acumulaci√≥n de regrets
    try:
        debug_regret_accumulation()
    except Exception as e:
        print(f"‚ùå Error en debug_regret_accumulation: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 2: Verificar simulaci√≥n de juegos
    try:
        debug_game_simulation()
    except Exception as e:
        print(f"‚ùå Error en debug_game_simulation: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 3: Verificar matem√°tica CFR
    try:
        debug_cfr_math()
    except Exception as e:
        print(f"‚ùå Error en debug_cfr_math: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nüéØ CONCLUSIONES:")
    print("   1. ¬øLos regrets cambian despu√©s de un paso? (Ver output arriba)")
    print("   2. ¬øLa simulaci√≥n genera payoffs diversos? (Ver output arriba)")
    print("   3. ¬øLos info sets se mapean correctamente? (Ver output arriba)")
    print("   4. Si todo parece correcto, el problema est√° en la l√≥gica CFR interna.")

if __name__ == "__main__":
    main() 